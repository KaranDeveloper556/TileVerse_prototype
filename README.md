<p align="center">
    <img src="https://i.pinimg.com/736x/8d/68/62/8d68625d10f2498b01d38ce3db0b1c02.jpg" alt="Forest Tile" width="400">
</p>

<h1 align="center">Generative AI for Tile Image Creation: Powered by Stable Diffusion</h1>

<p align="center">
    <img src="https://img.shields.io/badge/Project-IIT%20Bombay%20Techfest%20Pulse-brightgreen" alt="Project Status">
</p>

<p align="center">
    <b>Welcome to my project submission for the IIT Bombay Techfest Pulse competition! üöÄ</b> This project demonstrates how we can leverage cutting-edge <b>Generative AI</b> techniques to automatically generate high-quality <b>tilesets for game development</b>. The AI model used is <b>Stable Diffusion</b>, a deep learning model capable of transforming text prompts into stunning images.
</p>

<hr>

<h2>üîç About the Project</h2>

<p>
    In this project, I created a generative AI pipeline for <b>automatically generating tiles for game environments</b> using <b>Stable Diffusion</b>. The AI takes a <b>text description</b> of a tile (e.g., "forest landscape" or "desert terrain") and generates a corresponding image that can be used directly in game development.
</p>

<h3>Features:</h3>
<ul>
    <li><b>Text-to-Image Generation:</b> Generate game tiles with simple text prompts.</li>
    <li><b>High-Quality Results:</b> Utilizes the Stable Diffusion XL model to produce visually rich and detailed images.</li>
    <li><b>Optimized for Speed:</b> Runs efficiently on GPUs to provide quick results.</li>
</ul>

<hr>

<h2>‚öôÔ∏è Technology Stack</h2>

<ul>
    <li><b>AI/ML Framework:</b> <a href="https://huggingface.co/CompVis/stable-diffusion-v-1-4-original">Stable Diffusion</a></li>
    <li><b>Backend Framework:</b> <a href="https://pytorch.org/">PyTorch</a></li>
    <li><b>Diffusion Model Library:</b> <a href="https://huggingface.co/docs/diffusers">diffusers</a></li>
    <li><b>Model Optimization:</b> <a href="https://huggingface.co/docs/accelerate">accelerate</a></li>
    <li><b>Image Processing:</b> <a href="https://pillow.readthedocs.io/en/stable/">PIL</a></li>
    <li><b>Environment:</b> Google Colab, CUDA (GPU support)</li>
</ul>

<hr>

<h2>üöÄ How It Works</h2>

<h3>1. Model Setup</h3>
<p>
    I used the <b>Stable Diffusion XL model</b> to generate tiles from textual prompts. The model was loaded using the Hugging Face <code>diffusers</code> library, which provides a high-level API to interact with diffusion models.
</p>

<h3>2. Image Generation Pipeline</h3>
<p>
    Given a text prompt like <code>"A forest tile with trees and sunlight"</code>, the pipeline:
    <ol>
        <li>Loads the model.</li>
        <li>Sends the prompt through the diffusion model.</li>
        <li>Generates an image with realistic details based on the description.</li>
    </ol>
</p>

<h3>3. Customizable Parameters</h3>
<ul>
    <li><b>Guidance Scale:</b> Control how strongly the generated image matches the prompt.</li>
    <li><b>Inference Steps:</b> Adjust the number of steps for finer details or quicker results.</li>
</ul>

<hr>

<h2>üì¶ Installation & Setup</h2>

<h3>Run on Google Colab (Recommended)</h3>
<p>
    1. Open <a href="https://colab.research.google.com/">Google Colab</a>.
</p>
<p>
    2. Install the necessary libraries by running the following command:
</p>
<pre><code>!pip install diffusers transformers torch torchvision accelerate safetensors</code></pre>
<p>
    3. Run the Python code below to generate your tiles.
</p>

<pre><code>
import torch
from diffusers import DiffusionPipeline

# Initialize the diffusion pipeline
pipe = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16"
)

# Move to GPU if available
device = "cuda" if torch.cuda.is_available() else "cpu"
pipe.to(device)
print(f"Pipeline loaded to device: {device}")

# Generate an image from a prompt
prompt = "A peaceful forest landscape with trees and sunlight"
result = pipe(prompt=prompt)

# Retrieve the generated image
image = result.images[0]

# Display the image
image.show()

# Save the image
image.save("forest_tile.png")
</code></pre>

<hr>

<h2>üé® Example Output</h2>

<p>Here‚Äôs an example of a tile generated by the model from the prompt <code>"A forest landscape with trees and sunlight"</code>:</p>

<p align="center">
    <img src="https://i.pinimg.com/736x/e2/46/f3/e246f35ca13c760b0071e96be31a9ba2.jpg" alt="Forest Tile" width="400">
</p>

<p>You can customize the text prompt to generate different tiles based on your game's needs.</p>

<hr>

<h2>üîß Customization & Usage</h2>

<h3>Adjusting Model Parameters</h3>
<p>You can adjust the following parameters for better control over the generated tiles:</p>
<ul>
    <li><b>guidance_scale</b>: Controls the strength of adherence to the prompt (higher values give more detailed results).</li>
    <li><b>num_inference_steps</b>: Adjust the number of steps for image generation (more steps = higher quality).</li>
</ul>

<p>Example:</p>
<pre><code>
result = pipe(prompt="A desert terrain with sand dunes", guidance_scale=7.5, num_inference_steps=50)
</code></pre>

<h3>Batch Image Generation</h3>
<p>If you want to generate multiple tiles at once, you can pass a list of prompts:</p>
<pre><code>
prompts = ["A lush forest tile", "A dry desert terrain", "A snowy mountain landscape"]
result = pipe(prompt=prompts, batch_size=len(prompts))
</code></pre>

<hr>

<h2>üßë‚Äçüíª Try It Yourself</h2>

<p>Clone this repository and run the code in your local environment or on Google Colab to start generating your own game tiles with the power of generative AI!</p>

<pre><code>
git clone https://github.com/your-username/ai-tile-generator.git
cd ai-tile-generator
# Run the script
python generate_tiles.py
</code></pre>

<hr>

<h2>üí° Future Improvements</h2>

<p>In future iterations, I plan to:</p>
<ul>
    <li>Integrate more <b>game assets</b> like characters, environments, and objects.</li>
    <li>Provide a <b>web interface</b> for users to generate tiles without coding.</li>
    <li>Experiment with <b>fine-tuning the model</b> on custom datasets for more specific game environments.</li>
</ul>

<hr>

<h2>ü§ñ Acknowledgments</h2>

<ul>
    <li>Hugging Face for the <b>Diffusers</b> library and access to Stable Diffusion models.</li>
    <li><b>Google Colab</b> for providing free GPU resources.</li>
    <li>The <b>IIT Bombay Techfest Pulse competition</b> for providing this opportunity to showcase innovative AI projects.</li>
</ul>

<hr>

<h3 align="center"><b>üöÄ Let's build the future of game development with AI!</b></h3>
